{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Upload zip file\n",
        "uploaded = files.upload()  # Select nexar_collision_prediction.zip\n",
        "\n",
        "# Extract zip\n",
        "zip_path = list(uploaded.keys())[0]\n",
        "extract_path = '/content/nexar_collision_prediction'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Set dataset paths\n",
        "dataset_path = os.path.join(extract_path, 'train')\n",
        "positive_path = os.path.join(dataset_path, 'positive')\n",
        "negative_path = os.path.join(dataset_path, 'negative')\n",
        "\n",
        "print(f'Positive videos: {len(os.listdir(positive_path))}')\n",
        "print(f'Negative videos: {len(os.listdir(negative_path))}')\n"
      ],
      "metadata": {
        "id": "uuVPFkDu_qhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_video_paths(folder_path, label):\n",
        "    videos = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(('.mp4', '.avi', '.mov')):\n",
        "            videos.append({'file_path': os.path.join(folder_path, file), 'label': label})\n",
        "    return videos\n",
        "\n",
        "positive_videos = load_video_paths(positive_path, 1)\n",
        "negative_videos = load_video_paths(negative_path, 0)\n",
        "\n",
        "video_df = pd.DataFrame(positive_videos + negative_videos)\n",
        "print(f'Total videos loaded: {len(video_df)}')\n",
        "video_df.head()\n"
      ],
      "metadata": {
        "id": "f_pQJg9X_vKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_frames(video_path, max_frames=50):\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    step = max(1, total_frames // max_frames)\n",
        "\n",
        "    for i in range(0, total_frames, step):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "# Example: extract frames from first positive video\n",
        "sample_frames = extract_frames(video_df['file_path'].iloc[0])\n",
        "print(f'Extracted {len(sample_frames)} frames from video.')\n"
      ],
      "metadata": {
        "id": "LRDOcQhW_xX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_df['num_frames'] = video_df['file_path'].apply(lambda x: len(extract_frames(x, max_frames=20)))\n",
        "processed_csv_path = '/content/processed_data.csv'\n",
        "video_df.to_csv(processed_csv_path, index=False)\n",
        "print(f'Processed metadata saved at {processed_csv_path}')\n"
      ],
      "metadata": {
        "id": "6d6IDOZs_1d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyGithub\n",
        "\n",
        "from github import Github\n",
        "\n",
        "token = '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'\n",
        "repo_name = 'sara23523/project'\n",
        "\n",
        "g = Github(token)\n",
        "repo = g.get_repo(repo_name)\n",
        "\n",
        "# Read CSV content\n",
        "with open(processed_csv_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Create a new file in the repo\n",
        "repo.create_file(\"processed_data.csv\", \"Add processed Nexar video metadata\", content)\n",
        "print(\"Processed data uploaded to GitHub successfully!\")\n"
      ],
      "metadata": {
        "id": "nI48pG4C_4WF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}